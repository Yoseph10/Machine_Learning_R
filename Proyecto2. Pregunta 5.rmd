---
title: "Proyecto2"
author: "Claudia Villena"
date: "13/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Objetivo: buscaremos predecir las ventas de asientos de automóvil, de manera cuantitativa

a) Divida el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba.

```{r, include=FALSE}

#install.packages( "gbm" )
#install.packages( "tree" )
#install.packages( "ISLR2" )
#install.packages( "BART" )
#install.packages( "randomForest")
#install.packages( "Carseats")

library(gbm)
library(BART)

#### Importamos la data:
library(tree)
library(ISLR2)
attach(Carseats)
View(Carseats)
```

```{r}
set.seed (1)
train = sample (1: nrow(Carseats), nrow(Carseats) / 2)
test = (1:nrow(Carseats))[-train]
```

```{r}
train
```


```{r}
test
```


b) Ajuste un arbol de regresion al conjunto de entrenamiento. Interprete los resultados. ¿Que valor de MSE obtienes para el conjunto de prueba?

```{r}
tree.Carseats = tree(Sales ∼., Carseats , subset = train)
tree.Carseats.sum = summary(tree.Carseats)
tree.Carseats.sum
```


```{r}
#Observamos el grafico: 
plot(tree.Carseats)
text(tree.Carseats , pretty = 0)
```

Respuesta: 
En este caso, solo se emplearon 6 variables para construir el arbol. Estas variables son high, la calidad de la ubicación de las estanterías (Shelveloc), el precio cobrado por el competidor en cada ubicación (Comprice), la población regional (Population), el precio de los asientos en cada lugar (Price) y la edad de la población (Age) 

```{r}
used_vars <- as.character(tree.Carseats.sum$used)
used_vars
```

Además,se tienen 11 nodos terminales en el árbol. 

En lo que respecta a la evaluación del modelo, este presenta un Residual mean deviance de: 2.736873

```{r, INCLUDE = FALSE}
Carseats.test = predict( tree.Carseats, newdata=Carseats[test,] )
test.MSE = mean( ( Carseats.test - Carseats[test,]$Sales )^2 )
print( test.MSE )
```


c) Utilice la validacion cruzada para determinar el nivel optimo de complejidad del arbol. ¿Podra el arbol mejorar el MSE del conjunto de prueba?

```{r}
cv.Carseats <- cv.tree(tree.Carseats)
plot(cv.Carseats$size, cv.Carseats$dev, type = "b", xlim = c(2, 12))
tree.min <- which.min(cv.Carseats$dev)
points(tree.min, cv.Carseats$dev[tree.min], col = "red", cex = 2, pch = 20)
```
Seleccionamos el mejor nivel de complejidad del arbol. Ahora empleamos ese nivel de nodos para el árbol:  

```{r}
prune.Carseats <- prune.tree(tree.Carseats , best = 5)
plot(prune.Carseats)
text(prune.Carseats , pretty = 0)
```

Respuesta: 
El tamaño óptimo será de 5 nodos terminales 

Al probar el modelo en la data de prueba, se observa que el MSE asociado al árbol de decisión es:  2.736873

```{r}
yhat <- predict(tree.Carseats , newdata = Carseats[-train , ])
Carseats.test <- Carseats[-train, "Sales"]
plot(yhat , Carseats.test)
abline (0, 1)
mean (( yhat - Carseats.test)^2)
```


d) Utilice el metodo bagging para analizar estos datos. ¿Que valor de MSE obtienes para el conjunto de prueba? Use la funcion importance() para determinar que variables son las mas importantes.
```{r}
dim(Carseats)
```

```{r, INCLUDE = FALSE}
#install.packages( "randomForest" )
set.seed (1)
library(randomForest)
bag.Carseats <- randomForest(Sales ∼ ., data = Carseats, subset = train , mtry = 12, importance = TRUE)
summary(bag.Carseats)
```


Evaluamos el performance del modelo:

```{r, INCLUDE = FALSE}
Carseats.test <- Carseats[-train, "Sales"]

yhat.bag <- predict(bag.Carseats , newdata = Carseats[-train , ])
plot(yhat.bag , Carseats.test)
abline (0, 1)
mean (( yhat.bag - Carseats.test)^2)
```

Identificamos  la importancia de los predictores del modelo generado:

```{r}
importance.bag = importance( bag.Carseats )
print( importance.bag[ order( importance.bag[,1] ), ] )
```


Respuesta: 
Se observa que el MSE asociado a este arbol es de 2.162261

Además, se identifica que las variables más importantes del modelo considerando  el aumento en el %IncMSE, son: High, la calidad de la ubicación de la estantería (Shelveloc), el precio de las sillas (price) y el precio del competidor en la ubicación (CompPrice). Es decir, que cuando se excluyen estas variables del modelo, iniciando por la calidad de la ubicación de las estanterías (ShelveLoc), se genera un aumento significativo del MSE. Esto se observa en la siguiente tabla:  

```{r}
importance.bag
```


e) Utilice Random forest para analizar estos datos. ¿Que valor de MSE obtienes para el conjunto de prueba? Use la funcion importance() para determinar que variables son las mas importantes.Describa el efecto de m, el numero de variables consideradas en cada division, sobre la tasa de error obtenida.

Sabemos que por default randomForest() emplea p/3 variables. En este ejercicio se emplearán mtry = 4, donde m= √p. 

```{r}
set.seed (1)
rf.Carseats <- randomForest(Sales ∼ ., data = Carseats ,
                          subset = train , mtry = 4, importance = TRUE)
yhat.rf <- predict(rf.Carseats, newdata = Carseats[-train , ])
mean (( yhat.rf - Carseats.test)^2)
```
Observamos que con m = 4, tenemos un Test MSE  de 2.12137

Vemos la importancia de las variables: 

```{r}
importance.ran = importance(rf.Carseats)
importance.ran
```

A su vez, al medir la importancia de las variables mediente el aumento del %IncMSE, resaltan: High, Price, Shelveloc, CompPrice. Es decir, al quitar a estas variables, el MSE del modelo aumenta.  En el caso de High, el MSE aumenta en un 64.16%.  Esto se observa en el siguiente gráfico: 

```{r}
varImpPlot(rf.Carseats)
```
Aumentamos el número de variables para identificar su efecto en la tasa de error obtenida: 

Primero trabajamos con 6 variables: 
```{r}
set.seed (1)
rf.Carseats <- randomForest(Sales ∼ ., data = Carseats ,
                          subset = train , mtry = 6, importance = TRUE)
yhat.rf <- predict(rf.Carseats, newdata = Carseats[-train , ])
mean (( yhat.rf - Carseats.test)^2)
```
MSE:  Vemos que conforme aumenta el tamaño de m, también lo hace el MSE. En este caso sube a 2.176362

Ahora aumentamos el tamaño de m a 10.  

```{r}
set.seed (1)
rf.Carseats10 <- randomForest(Sales ∼., data = Carseats , subset = train , mtry = 10, importance = TRUE)
yhat.rf10 <- predict(rf.Carseats10, newdata = Carseats[-train , ])
mean (( yhat.rf10 - Carseats.test)^2)
```
MSE: Vemos que el MSE se reduce a 2.152985


Respuesta: 
El MSE en el grupo de testeo es de 2.667767. Vemos una reducción en el MSE respecto a Bagging, cuando el modelo incluye un m = 10 . Pero el m= 4 presenta el mejor MSE al ser de 2.12137. 



De igual forma, como se observó en el ejercicio, al aumentar el tamaño de n de 6 a 10 variables en el modelo, el MSE varia, subiendo cuando el m= 6 y bajando con m= 10. 

f) Analice la data utilizando boosting:

```{r}
set.seed (1)
boost.Carseats <- gbm(Sales ∼ ., data = Carseats[train , ],
                    distribution = "gaussian", n.trees = 5000,
                    interaction.depth = 4)
summary(boost.Carseats)
```


Analizamos el performance del modelo: 

```{r}
yhat.boost <- predict(boost.Carseats ,
                      newdata = Carseats[-train , ], n.trees = 5000)
mean (( yhat.boost - Carseats.test)^2)
```
Respuesta: Al emplear boosting, que posee un proceso de aprendizaje continuo con árboles ligados, se observa que el MSE se reduce a 1.740801. Esto implica una mejora en la capacidad predictiva del modelo que emplea Boosting por sobre Random Forests y Bagging.

Asimismo, se observa que las variables, High, Price (precio) y Sherveloc (la calidad de la ubicación de las estanterías) son las más importantes.
